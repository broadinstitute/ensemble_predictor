{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected run time: 2 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container {  !important;    } div.output_wrapper .output { padding-left: 14px; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML \n",
    "display(HTML(\n",
    "    \"<style>.container {  !important;\\\n",
    "    } div.output_wrapper .output { padding-left: 14px; }</style>\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively, pip3 or other command to install for the appropriate version of python\n",
    "#on your machine.\n",
    "! pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# you may need to restart your kernel before this step\n",
    "import ensemble_predictor as ep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some example data has been included in this package to illustrate running the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load cell characteristics to use in predicting\n",
    "X = ep.read_hdf5('sample_features.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load post-CRISPR knockout viability estimates\n",
    "Y = ep.read_hdf5(\"sample_achilles_effects.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(693, 138) (693, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            BRAF (673)  ERBB2 (2064)\n",
      "ACH-000004   -0.032777     -0.289101\n",
      "ACH-000005   -0.005177     -0.379375\n",
      "ACH-000007   -0.157759     -0.531896\n",
      "ACH-000009   -0.170781     -1.103794\n",
      "ACH-000011   -0.026527     -0.514542\n"
     ]
    }
   ],
   "source": [
    "print(Y[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running the full ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll try just running the full ensemble first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following models:\n",
      "['Histology', 'KitchenSink', 'Expression', 'Mutation', 'Fusion', 'GSEA', 'CN', 'Methylation', 'AllExpression', 'AllGenomics', 'Mutation+Exp', 'CN+Exp', 'Methylation+Exp']\n",
      "aligning features\n",
      "creating models\n",
      "creating ensemble\n",
      "fitting ensemble to 2 columns\n",
      "25.421377 elapsed, 50% complete, 25.421377 estimated remaining\n",
      "51.530469 elapsed, 100% complete, 0.000000 estimated remaining\n",
      "saving results to test_results/save0_2\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(\"test_results\")\n",
    "ep.run_subset(X=X, Y=Y, directory=\"test_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reviewing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.read_csv(\"test_results/save0_2_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each fold's Pearson correlation score is given in the columns score0, score1...\n",
    "summary['average_score'] = summary[[s for s in summary.columns\n",
    "                                   if s.startswith('score')]\n",
    "                                  ].median(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            gene            model  average_score\n",
      "10    BRAF (673)     Mutation+Exp       0.804767\n",
      "1     BRAF (673)      KitchenSink       0.776977\n",
      "9     BRAF (673)      AllGenomics       0.760146\n",
      "3     BRAF (673)         Mutation       0.758679\n",
      "4     BRAF (673)           Fusion       0.728399\n",
      "0     BRAF (673)        Histology       0.700874\n",
      "11    BRAF (673)           CN+Exp       0.691363\n",
      "5     BRAF (673)             GSEA       0.676606\n",
      "7     BRAF (673)      Methylation       0.660698\n",
      "8     BRAF (673)    AllExpression       0.649712\n",
      "12    BRAF (673)  Methylation+Exp       0.644351\n",
      "6     BRAF (673)               CN       0.612224\n",
      "2     BRAF (673)       Expression       0.610994\n",
      "14  ERBB2 (2064)      KitchenSink       0.515738\n",
      "15  ERBB2 (2064)       Expression       0.506470\n",
      "23  ERBB2 (2064)     Mutation+Exp       0.489823\n",
      "24  ERBB2 (2064)           CN+Exp       0.470678\n",
      "21  ERBB2 (2064)    AllExpression       0.462541\n",
      "19  ERBB2 (2064)               CN       0.461909\n",
      "22  ERBB2 (2064)      AllGenomics       0.450540\n",
      "25  ERBB2 (2064)  Methylation+Exp       0.420525\n",
      "20  ERBB2 (2064)      Methylation       0.377610\n",
      "18  ERBB2 (2064)             GSEA       0.337067\n",
      "17  ERBB2 (2064)           Fusion       0.335346\n",
      "13  ERBB2 (2064)        Histology       0.296323\n",
      "16  ERBB2 (2064)         Mutation       0.250832\n"
     ]
    }
   ],
   "source": [
    "# You should see with BRAF (673)'s top model with average\n",
    "# score near 0.8. \n",
    "# The top scoring model for ERBB2 (2064) should be above 0.5\n",
    "print(summary[['gene', 'model', 'average_score']].sort_values('average_score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the results found from averaging the correlations of out-of-sample predictions with the true gene effect across folds. We can load the actual predictions for a specific model, such as `\"KitchenSink\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "kitchen_sink = pd.read_csv('test_results/save0_2_KitchenSink_predictions.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRAF (673)      0.767470\n",
      "ERBB2 (2064)    0.473728\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(kitchen_sink.corrwith(Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the ensemble for a specific subset of models, columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may only be interested in the results of particular group of models. Additionally, if we are running multiple ensembles in parallel, we may want to divide the problem by the columns in `Y` to be predicted. This will run the ensemble for only two models on only the last column. Note that the first part of the file names `\"save1_2\"` indicates that this includes columns 1-2 using python's indexing convention (starts at 0, second value not included)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the following models:\n",
      "['Expression', 'Mutation']\n",
      "aligning features\n",
      "creating models\n",
      "creating ensemble\n",
      "fitting ensemble to 1 columns\n",
      "saving results to test_results/save1_2\n"
     ]
    }
   ],
   "source": [
    "ep.run_subset(X=X, Y=Y, start_col=1, n_col=1, included_models=['Expression', 'Mutation'],\n",
    "              directory=\"test_results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a custom model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A few classes are defined that inherit from sklearn's `RandomForestRegressor` and are useful for subsetting features. `KFilteredForest` filters features for the top `k` with highest correlation to the target. Here, we'll build a model that will use only the top 100 most correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ep.KFilteredForest(max_depth=4, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X, Y['BRAF (673)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRAF (673)_Hot                  0.730074\n",
      "BRAF (673)_CN                   0.102663\n",
      "disease_sutype_melanoma_Cell    0.028314\n",
      "BRAF (673)_Dam                  0.026816\n",
      "BRAF (673)_Exp                  0.017251\n",
      "ERBB2 (2064)_Exp                0.014911\n",
      "ERBB2_4_MethCpG                 0.012854\n",
      "ERBB2_3_MethCpG                 0.009346\n",
      "ERBB2 (2064)_CN                 0.005279\n",
      "disease_colorectal_Cell         0.004889\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# You should see BRAF (673)_Hot with more than 0.7 feature importance\n",
    "print(pd.Series(model.feature_importances_, index=model.feature_names\n",
    "               ).sort_values(ascending=False)[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
